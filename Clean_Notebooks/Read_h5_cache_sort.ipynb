{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a7b479",
   "metadata": {},
   "source": [
    "## 1. Import .h5 format files and use Spikeinterface and Spyking Circus for Sorting\n",
    "\n",
    "This notebook is the initial step in MEA analysis. We use Spyking Circus via Spikeinterface for Spikesorting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2467d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "#import spikeinterface modules\n",
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.toolkit as st\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.widgets as sw\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "#import everything else\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# import pandas as pd\n",
    "# import h5py\n",
    "# import McsPy\n",
    "# import sys, importlib, os\n",
    "# import McsPy.McsData\n",
    "# import McsPy.McsCMOS\n",
    "# from McsPy import ureg, Q_\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import cm\n",
    "# import seaborn as sns\n",
    "\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78389dc3",
   "metadata": {},
   "source": [
    "Define directories.\n",
    "\n",
    "In the scripts an outputdirectory for every file will be created containing the sorting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e8926a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main directory of the folder to analyse\n",
    "filedirec = r\"D:\\MEA_DATA_Aachen\\ANALYZED\\20210708_mouse_cortex_div_\"\n",
    "# sub directory with the actual data\n",
    "inputdirectory = r\"D:\\MEA_DATA_Aachen\\PREPROCESSED\\20210708_mouse_cortex_div_\"\n",
    "\n",
    "os.chdir(inputdirectory)\n",
    "\n",
    "\n",
    "# probe_file needs to be the same for every recording with the MCS MEA 256\n",
    "probe_file=\"C:/Users/User/Documents/JO/gitkraken/MEA_analysis/Spikesorting/MCS_MEA_256_100µM_spacing.prb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bc1dfc",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46edd304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function MCSH5RecordingExtractor.__del__ at 0x000001C57F2640D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\spikeextractors\\extractors\\mcsh5recordingextractor\\mcsh5recordingextractor.py\", line 34, in __del__\n",
      "    self._rf.close()\n",
      "AttributeError: 'MCSH5RecordingExtractor' object has no attribute '_rf'\n"
     ]
    }
   ],
   "source": [
    "def divide_recording_to_sub(recording, sublength_seconds):\n",
    "  \n",
    "    '''\n",
    "    parameters: recording = recording extractor\n",
    "                sublength_seconds = int, how long shall the subrecordings be\n",
    "                \n",
    "    returns: dictionary with key=str: sec_xxx-xxx, value=subrecording extractor\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    subrecording_dic = {}\n",
    "    fs = recording.get_sampling_frequency()\n",
    "    recording_length = recording.get_num_frames()\n",
    "    recording_seconds = recording_length/fs\n",
    "    end_frame = int(recording_seconds)\n",
    "    \n",
    "    for snippet in range(0, end_frame, sublength_seconds):\n",
    "        sub_start = snippet\n",
    "        sub_end = snippet + sublength_seconds\n",
    "        if sub_end > end_frame:\n",
    "            sub_end = end_frame\n",
    "        sub_str = 'sec_'+str(sub_start)+'-'+str(sub_end)\n",
    "    \n",
    "        subrecording_dic[sub_str] = se.SubRecordingExtractor(\n",
    "            recording_cmrprobe, start_frame = sub_start*fs,\n",
    "            end_frame = sub_end*fs)\n",
    "    \n",
    "    return subrecording_dic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_cache_for_subrecordings(subrecording_dic, filebase, outpath):\n",
    "  \n",
    "    '''\n",
    "    parameters: \n",
    "        subrecording_dic = dictionary with all subrecordings to be cached\n",
    "        filebase = str, name of the based file\n",
    "        outpath = directory where files will be directed\n",
    "        \n",
    "    returns: \n",
    "        print statement after function is finished, will dump and save\n",
    "        the cached as .pkl in outpath\n",
    "    '''\n",
    "    for key in subrecording_dic:\n",
    "        sub_cache = se.CacheRecordingExtractor(\n",
    "            subrecording_dic[key])\n",
    "        filepath = os.path.join(\n",
    "            outpath, filebase+str(key)+'_filtered_data.dat'\n",
    "            ).replace('\\\\','/')\n",
    "        sub_cache.move_to(filepath) \n",
    "        sub_cache.dump_to_dict()\n",
    "        filepathpickle = os.path.join(\n",
    "            outpath, filebase+str(key)+'_recording.pkl'\n",
    "            ).replace('\\\\','/')\n",
    "        sub_cache.dump_to_pickle(filepathpickle)\n",
    "        \n",
    "    return 'Finished dumping the subrecords. To load, use the load_dumped_recordings function'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_dumped_subrecordings(directory, filebase):\n",
    "   \n",
    "    '''\n",
    "    parameters:\n",
    "        diretory = where subrecordings are saved\n",
    "        filebase = namebase of the recording to be loaded\n",
    "        \n",
    "    returns:\n",
    "        a dictionary with keys=dictkeys ('sec_xxx-xxx'), values=subrecordings\n",
    "        extractors\n",
    "    '''\n",
    "    beforedirectory = os.getcwd()\n",
    "    os.chdir(directory)\n",
    "    subrecording_dic = {}\n",
    "    filelist = glob.glob('*.pkl')\n",
    "    for file in filelist:\n",
    "        key = file.split(filebase)[1].split('.')[0].split('_recording')[0]\n",
    "        subrecording_dic[key]=se.load_extractor_from_pickle(file)\n",
    "    \n",
    "    os.chdir(beforedirectory)\n",
    "    return subrecording_dic\n",
    "\n",
    "\n",
    "\n",
    "def run_spykingcircus_on_sub(subrecording_dic, directory):\n",
    "    \n",
    "    '''\n",
    "    parameters:\n",
    "        subrecording dic = a dictionary with keys=dictkeys ('sec_xxx-xxx'), \n",
    "        values=subrecordings\n",
    "        directory = path where subrecordings are saved\n",
    "        \n",
    "    returns:\n",
    "        a dictionary with key = dictkeys ('sec_xxx-xxx'), values = sortings\n",
    "\n",
    "    '''\n",
    "    sorted_dic={}\n",
    "    for key in subrecording_dic:\n",
    "        outpath_SC=os.path.join(outpath, 'sorted_'+str(key)).replace('\\\\', '/')\n",
    "        '''\n",
    "        try:\n",
    "            os.mkdir(outpath_SC)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % outpath)\n",
    "        else:\n",
    "            print (\"Successfully created the directory %s \" % outpath)\n",
    "        '''\n",
    "        sorted_dic[key]=ss.run_spykingcircus(\n",
    "            subrecording_dic[key], output_folder=outpath_SC\n",
    "            )\n",
    "\n",
    "    return sorted_dic\n",
    "    \n",
    "\n",
    "\n",
    "def load_dumped_sorted_dic(outpath):\n",
    "\n",
    "    '''\n",
    "    parameters: \n",
    "        directory where sortings of spyking circus are saved\n",
    "        \n",
    "    returns:\n",
    "        dictionary with key = dictkeys ('sec_xxx-xxx'), values = sortings\n",
    "    '''\n",
    "    sorted_dic = {}\n",
    "    filelist = glob.glob('*sorted*')\n",
    "    for file in filelist:\n",
    "        key = file.split('sorted_')[1]\n",
    "        sorted_dic[key]=se.SpykingCircusSortingExtractor(file)\n",
    "        \n",
    "    return sorted_dic\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49341914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the filelist of all .h5 files\n",
    "filelist = glob.glob('*.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d0087fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = filelist[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9dfb2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-07-08T11-17-35__mousecortex_div_aCSF_IDm001_10µMCNQX_spont_2__.h5']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81f75214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on 2021-07-08T11-17-35__mousecortex_div_aCSF_IDm001_10µMCNQX_spont_2__.h5\n",
      "Successfully created the directory D:/MEA_DATA_Aachen/ANALYZED/20210708_mouse_cortex_div_/_output_Spikesorting_22072021_mousecortex_div_aCSF_IDm001_10µMCNQX_spont_2_spikesorting \n",
      "RUNNING SHELL SCRIPT: D:\\MEA_DATA_Aachen\\ANALYZED\\20210708_mouse_cortex_div_\\_output_Spikesorting_22072021_mousecortex_div_aCSF_IDm001_10µMCNQX_spont_2_spikesorting\\sorted_sec_0-120\\run_spykingcircus.bat\n"
     ]
    },
    {
     "ename": "SpikeSortingError",
     "evalue": "Spike sorting failed: spykingcircus returned a non-zero exit code. You can inspect the runtime trace in the spykingcircus.log of the output folder.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spikesorters\\basesorter.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, raise_error, parallel, n_jobs, joblib_backend)\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecording\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecording_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecording\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_folders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spikesorters\\spyking_circus\\spyking_circus.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, recording, output_folder)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mretcode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spykingcircus returned a non-zero exit code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: spykingcircus returned a non-zero exit code",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSpikeSortingError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-8dcc65777614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mloaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dumped_subrecordings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilebase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[0msorted_dic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_spykingcircus_on_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# the dic can be loaded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-05e7736d0357>\u001b[0m in \u001b[0;36mrun_spykingcircus_on_sub\u001b[1;34m(subrecording_dic, directory)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully created the directory %s \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0moutpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         '''\n\u001b[1;32m--> 112\u001b[1;33m         sorted_dic[key]=ss.run_spykingcircus(\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0msubrecording_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutpath_SC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spikesorters\\sorterlist.py\u001b[0m in \u001b[0;36mrun_spykingcircus\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mspike\u001b[0m \u001b[0msorted\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m     \"\"\"\n\u001b[1;32m--> 523\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrun_sorter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'spykingcircus'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spikesorters\\sorterlist.py\u001b[0m in \u001b[0;36mrun_sorter\u001b[1;34m(sorter_name_or_class, recording, output_folder, delete_output_folder, grouping_property, parallel, verbose, raise_error, n_jobs, joblib_backend, **params)\u001b[0m\n\u001b[0;32m     88\u001b[0m                          verbose=verbose, delete_output_folder=delete_output_folder)\n\u001b[0;32m     89\u001b[0m     \u001b[0msorter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0msorter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparallel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoblib_backend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjoblib_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[0msortingextractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spikesorters\\basesorter.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, raise_error, parallel, n_jobs, joblib_backend)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m                 raise SpikeSortingError(f\"Spike sorting failed: {err}. You can inspect the runtime trace in \"\n\u001b[0m\u001b[0;32m    170\u001b[0m                                         f\"the {self.sorter_name}.log of the output folder.'\")\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSpikeSortingError\u001b[0m: Spike sorting failed: spykingcircus returned a non-zero exit code. You can inspect the runtime trace in the spykingcircus.log of the output folder.'"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in filelist:\n",
    "    filename = i\n",
    "    print('Working on %s' %filename)\n",
    "\n",
    "\n",
    "    filebase = filename.split('__')[1]\n",
    "    \n",
    "    # for overview when the analysis was performed: create a timestring\n",
    "    timestr = strftime(\"%d%m%Y\")\n",
    "    outputdirectory = os.path.join(filedirec, '_output_Spikesorting_'+ timestr).replace('\\\\','/')\n",
    "    \n",
    "    probe_file=\"C:/Users/User/Documents/JO/gitkraken/MEA_analysis/Spikesorting/MCS_MEA_256_100µM_spacing.prb\"\n",
    "    #outputdirectory_SC='D:/Files_Reutlingen_Jenny/main_191021extra/191021_extra_Spikesorting/output_Spykingcirucs'\n",
    "    \n",
    "    # one outpath is created for every datafile\n",
    "    outpath=os.path.join(outputdirectory+'_'+filename.split('__')[1]+'_spikesorting').replace(\"\\\\\",\"/\")\n",
    "    try:\n",
    "        os.mkdir(outpath)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % outpath)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % outpath)\n",
    "        \n",
    "    \n",
    "    \n",
    "    os.chdir(outpath)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    1. Create subrecordings, Caches, run the spikesorter\n",
    "    '''\n",
    "    \n",
    "    # load in the recordings from the .h5 file\n",
    "    recording_MEA=se.MCSH5RecordingExtractor(\n",
    "        os.path.join(inputdirectory, filename), stream_id=0)\n",
    "    \n",
    "    # bandpassfilter the recording\n",
    "    recording_f = st.preprocessing.bandpass_filter(\n",
    "        recording_MEA, freq_min=150, freq_max=4500, filter_type='butter', order=2)\n",
    "    \n",
    "    \n",
    "    #remove bad channels automatically\n",
    "    recording_removed_bad = st.preprocessing.remove_bad_channels(\n",
    "        recording_MEA, seconds = 30)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # common reference\n",
    "    recording_cmr = st.preprocessing.common_reference(\n",
    "        recording_removed_bad, reference='median')\n",
    "    \n",
    "    # load the probe file\n",
    "    recording_cmrprobe=recording_cmr.load_probe_file(\n",
    "        probe_file=\"C:/Users/User/Documents/JO/gitkraken/MEA_analysis/Spikesorting/MCS_MEA_256_100µM_spacing.prb\")\n",
    "    \n",
    "    # divide the recording into subrecords, subrecords is a dictionary\n",
    "    subrecords = divide_recording_to_sub(recording_cmrprobe, 120)\n",
    "    \n",
    "    # create the cache for the subrecordings\n",
    "    create_cache_for_subrecordings(\n",
    "        subrecording_dic=subrecords, filebase=filebase, outpath=outpath)\n",
    "    \n",
    "    loaded = load_dumped_subrecordings(outpath, filebase)\n",
    "    \n",
    "    sorted_dic = run_spykingcircus_on_sub(loaded, outpath)\n",
    "    \n",
    "    # the dic can be loaded \n",
    "    sorted_dic = load_dumped_sorted_dic(outpath)\n",
    "    \n",
    "print('Finished the sorting-process.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc63d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mousecortex_div_aCSF_IDm001_nodrug_spont_1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filebase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b6430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
