{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02be400-61ff-41e9-b11c-b7a8aa2fe527",
   "metadata": {},
   "source": [
    "# Extraxtion of spikes and LFPs (local field potentials) from the rawdata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a781bf-c29f-4ac7-b8e7-e4f509edf200",
   "metadata": {},
   "source": [
    "Adjust the directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b9c299-8531-42ff-89ed-cb64419a0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptdirectory = r\"C:\\Users\\User\\Documents\\JO\\gitkraken\\MEA_analysis\\CSA_JO\"\n",
    "inputdirectory = r\"D:/MEA_DATA_Aachen/PREPROCESSED/20210517_cortex_div11\"\n",
    "\n",
    "outputdirectory = r\"D:/MEA_DATA_Aachen/ANALYZED/ID046_analysiert_22102021/analysis_17112021\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eda619-116c-40a6-83fe-38b2a0ff1df7",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57823e8d-9999-4c84-8725-a64a886eb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(scriptdirectory)\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import neo\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from hdfviewer.widgets.HDFViewer import HDFViewer\n",
    "from hdfviewer.widgets.PathSelector import PathSelector\n",
    "import McsPy\n",
    "import sys, importlib, os\n",
    "import McsPy.McsData\n",
    "import McsPy.McsCMOS\n",
    "from McsPy import ureg, Q_\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.widgets import Slider\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "from bokeh.palettes import Spectral11\n",
    "from scipy.signal import butter, lfilter, freqz, find_peaks, correlate, gaussian, filtfilt\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import McsPy\n",
    "import McsPy.McsData\n",
    "from McsPy import ureg, Q_\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from dep_Butterworth_Filter import butter_bandpass, butter_bandpass_filter\n",
    "import glob\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from dep_plot_signal_and_spikes import plot_signal_and_spikes_from_bandpassfilteredsignal\n",
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955c7cf-09c8-44f8-98b5-1080280de025",
   "metadata": {},
   "source": [
    "## Many functions are designed before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af1310-b214-4ed7-8b4a-e55d153db5f7",
   "metadata": {},
   "source": [
    "These are now imported as one chunk of code snippets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db1c41-bdf8-4240-ade9-1651de20c2ff",
   "metadata": {},
   "source": [
    "IMPORTANT: Some of these Functions are simply copied from MCS Py Data Tools Tutorials!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e56b941-a9cd-4bf0-9514-b8d0b2621af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_channel_infos(filedirectory, meafile):\n",
    "    channel_raw_data = McsPy.McsData.RawData(os.path.join(filedirectory, \n",
    "                                                          meafile))\n",
    "    print(channel_raw_data.recordings)\n",
    "    print(channel_raw_data.comment)\n",
    "    print(channel_raw_data.date)\n",
    "    print(channel_raw_data.clr_date)\n",
    "    print(channel_raw_data.date_in_clr_ticks)\n",
    "    print(channel_raw_data.file_guid)\n",
    "    print(channel_raw_data.mea_name)\n",
    "    print(channel_raw_data.mea_sn)\n",
    "    print(channel_raw_data.mea_layout)\n",
    "    print(channel_raw_data.program_name)\n",
    "    print(channel_raw_data.program_version)\n",
    "    analognumber = len(channel_raw_data.recordings[0].analog_streams.keys())\n",
    "    print('In total '+ str(analognumber) \n",
    "          + \" analog_streams were identified.\\n\")\n",
    "    for i in range(len(channel_raw_data.recordings[0].analog_streams.keys())):\n",
    "        keylist = []\n",
    "        stream = channel_raw_data.recordings[0].analog_streams[i]\n",
    "        for key in stream.channel_infos.keys():\n",
    "                keylist.append(key)\n",
    "        channel_id = keylist[0]\n",
    "        datapoints = channel_raw_data.recordings[0].analog_streams[i].channel_data.shape[1]\n",
    "        samplingfrequency = stream.channel_infos[channel_id].sampling_frequency\n",
    "        ticks = stream.channel_infos[channel_id].info['Tick']\n",
    "        time = stream.get_channel_sample_timestamps(channel_id)\n",
    "        scale_factor_for_second = Q_(1,time[1]).to(ureg.s).magnitude\n",
    "        time_in_sec = time[0] * scale_factor_for_second\n",
    "        timelengthrecording_ms = time[0][-1]+ticks\n",
    "        timelengthrecording_s = (time[0][-1]+ticks)*scale_factor_for_second\n",
    "        print(\"analog_stream Nr. \" + str(i) + \": \")\n",
    "        print(\"datapoints measured = \" + str(datapoints))\n",
    "        print(\"sampling frequency = \" + str(samplingfrequency))\n",
    "        print(\"ticks = \" + str(ticks))\n",
    "        print(\"total recordingtime is: \" \n",
    "              + str(timelengthrecording_s) + \"seconds \\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_MEA_Signal(analog_stream, channel_idx, from_in_s=0, to_in_s=None):\n",
    "    '''\n",
    "    Extracts one Channels (channel_idx) Sginal \n",
    "    \n",
    "    :param analog_stream = the analogstream from one recording\n",
    "    :param channel_idx   = the channel index of the channel where you \n",
    "                            extract the values from\n",
    "    :param from_in_s     = starting point of the range you want to observe \n",
    "                            in seconds\n",
    "    :param to_in_s       = ending point of the range you want to observe. \n",
    "                            Default is None (i.e. whole range)\n",
    "    \n",
    "    Returns: the signal in uV, time stamps in sec, the sampling frequency\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    ids = [c.channel_id for c in analog_stream.channel_infos.values()]\n",
    "    channel_id = ids[channel_idx]\n",
    "    channel_info = analog_stream.channel_infos[channel_id]\n",
    "    sampling_frequency = channel_info.sampling_frequency.magnitude\n",
    "\n",
    "    # get start and end index\n",
    "    from_idx = max(0, int(from_in_s * sampling_frequency))\n",
    "    if to_in_s is None:\n",
    "        to_idx = analog_stream.channel_data.shape[1]\n",
    "    else:\n",
    "        to_idx = min(\n",
    "            analog_stream.channel_data.shape[1], \n",
    "            int(to_in_s * sampling_frequency)\n",
    "            )\n",
    "\n",
    "    # get the timestamps for each sample\n",
    "    time = analog_stream.get_channel_sample_timestamps(\n",
    "        channel_id, from_idx, to_idx\n",
    "        )\n",
    "\n",
    "    # scale time to seconds:\n",
    "    scale_factor_for_second = Q_(1,time[1]).to(ureg.s).magnitude\n",
    "    time_in_sec = time[0] * scale_factor_for_second\n",
    "\n",
    "    # get the signal\n",
    "    signal = analog_stream.get_channel_in_range(channel_id, from_idx, to_idx)\n",
    "\n",
    "    # scale signal to ÂµV:\n",
    "    scale_factor_for_uV = Q_(1,signal[1]).to(ureg.uV).magnitude\n",
    "    signal_in_uV = signal[0] * scale_factor_for_uV\n",
    "    \n",
    "    return signal_in_uV, time_in_sec, sampling_frequency, scale_factor_for_second\n",
    "\n",
    "\n",
    "def get_MEA_Channel_labels(np_analog_for_filter):\n",
    "    '''\n",
    "    Gives a List of all MEA Channel Labels (e.g. R12) in the order they appear\n",
    "    within the recording.\n",
    "    \n",
    "    :param analogstream_data = an numpy array shape(channels, data)\n",
    "    \n",
    "    '''\n",
    "    labellist = []\n",
    "    for i in range(0, len(np_analog_for_filter)):\n",
    "        #channel_idx = i\n",
    "        ids = [c.channel_id for c in analog_stream_0.channel_infos.values()]\n",
    "        channel_id = ids[i]\n",
    "        channel_info = analog_stream_0.channel_infos[channel_id]\n",
    "        #print(channel_info.info['Label'])\n",
    "        labellist.append(channel_info.info['Label'])\n",
    "    return labellist\n",
    "    \n",
    "\n",
    "#@jit(nopython=True)\n",
    "def detect_threshold_crossings(signal, fs, threshold, dead_time):\n",
    "    \"\"\"\n",
    "    Detect threshold crossings in a signal with dead time and return \n",
    "    them as an array\n",
    "\n",
    "    The signal transitions from a sample above the threshold to a sample \n",
    "    below the threshold for a detection and\n",
    "    the last detection has to be more than dead_time apart \n",
    "    from the current one.\n",
    "\n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param threshold: The threshold for the signal\n",
    "    :param dead_time: The dead time in seconds.\n",
    "    \"\"\"\n",
    "    dead_time_idx = dead_time * fs\n",
    "    threshold_crossings = np.diff(\n",
    "        (signal <= threshold).astype(int) > 0).nonzero()[0]\n",
    "    distance_sufficient = np.insert(\n",
    "        np.diff(threshold_crossings) >= dead_time_idx, 0, True\n",
    "        )\n",
    "    while not np.all(distance_sufficient):\n",
    "        # repeatedly remove all threshold crossings that violate the dead_time\n",
    "        threshold_crossings = threshold_crossings[distance_sufficient]\n",
    "        distance_sufficient = np.insert(\n",
    "            np.diff(threshold_crossings) >= dead_time_idx, 0, True\n",
    "            )\n",
    "    return threshold_crossings\n",
    "\n",
    "\n",
    "def get_next_minimum(signal, index, max_samples_to_search):\n",
    "    \"\"\"\n",
    "    Returns the index of the next minimum in the signal after an index\n",
    "\n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param index: The scalar index\n",
    "    :param max_samples_to_search: The number of samples to search for a \n",
    "                                    minimum after the index\n",
    "    \"\"\"\n",
    "    search_end_idx = min(index + max_samples_to_search, signal.shape[0])\n",
    "    min_idx = np.argmin(signal[index:search_end_idx])\n",
    "    return index + min_idx\n",
    "\n",
    "\n",
    "def align_to_minimum(signal, fs, threshold_crossings, search_range, first_time_stamp=0):\n",
    "    \"\"\"\n",
    "    Returns the index of the next negative spike peak for all threshold crossings\n",
    "\n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param threshold_crossings: The array of indices where the signal \n",
    "                                crossed the detection threshold\n",
    "    :param search_range: The maximum duration in seconds to search for the \n",
    "                         minimum after each crossing\n",
    "    \"\"\"\n",
    "    search_end = int(search_range*fs)\n",
    "    aligned_spikes = [get_next_minimum(signal, t, search_end) for t in threshold_crossings]\n",
    "    return np.array(aligned_spikes)\n",
    "\n",
    "\n",
    "def find_triggers(dset_trigger, tick):\n",
    "    \n",
    "    for i in range(0,len(dset_trigger)-1):\n",
    "        trigger_n=i\n",
    "        Trigger_An=dset_trigger[trigger_n]\n",
    "        diff_An=np.diff(Trigger_An)\n",
    "        peaks, _ = find_peaks(diff_An, height = 2000) #MEA60=0.75\n",
    "        peaks_off, _ = find_peaks(-diff_An, height = 2000) #\"\"\n",
    "        if len(peaks)>=0:\n",
    "            break\n",
    "    \n",
    "    if trigger_n ==0:\n",
    "        odd_peaks= peaks\n",
    "        odd_peaks_off= peaks_off\n",
    "    else:\n",
    "        odd_peaks=peaks\n",
    "        odd_peaks_off=peaks_off\n",
    "    #x=np.arange(len(Trigger_An))*tick\n",
    "    #plt.plot(x, Trigger_An)\n",
    "    return odd_peaks, odd_peaks_off, diff_An\n",
    "\n",
    "def spike_on_off(trigger_on, trigger_off, spikedic, tick):\n",
    "    \"\"\"\n",
    "    Takes the dictionary with all spikes and sorts them into either a dictionary for\n",
    "    spikes while trigger on (=ONdic) or off (=OFFdic)\n",
    "    \n",
    "    :param trigger_on =basically created through the find_triggers function \n",
    "                        and marks points were stimulation is turned on\n",
    "    :param trigger_off =see trigger_on but for stimulation off\n",
    "    :spikedic = dictionary of spikes for each electrode\n",
    "    :tick\n",
    "    \"\"\"\n",
    "    on=[]\n",
    "    off=[]\n",
    "    ONdic ={}\n",
    "    OFFdic={}\n",
    "    Trigger_An=[]\n",
    "    Trigger_Aus=[]\n",
    "    \n",
    "    if len(trigger_off)==0:\n",
    "        Trigger_An=[]\n",
    "    elif trigger_off[len(trigger_off)-1]>trigger_on[len(trigger_on)-1]:\n",
    "        Trigger_An=trigger_on*tick\n",
    "    else:\n",
    "        Trigger_An=[]\n",
    "        for n in range(0,len(trigger_on)-1):\n",
    "            Trigger_An.append(trigger_on[n]*tick)   \n",
    "        Trigger_An=np.array(Trigger_An)\n",
    "\n",
    "            \n",
    "    if len(trigger_on)==0:\n",
    "        Trigger_Aus=[]\n",
    "    elif trigger_off[0]>trigger_on[0]:\n",
    "        Trigger_Aus=trigger_off*tick\n",
    "    else:\n",
    "        Trigger_Aus=[]\n",
    "        for n in range(1,len(trigger_off)):\n",
    "            Trigger_Aus.append(trigger_off[n]*tick)\n",
    "        Trigger_Aus=np.array(Trigger_Aus)\n",
    "    \n",
    "    Trigger_Aus2=np.insert(Trigger_Aus,0,0)\n",
    "    \n",
    "    for key in spikedic:\n",
    "        ON = []\n",
    "        OFF = []\n",
    "        for i in spikedic[key]: #i mit 40 multiplizieren, da Trigger an und aus mit Tick multipliziert sind\n",
    "            if len(Trigger_An)==0:\n",
    "                OFF.append(i)\n",
    "            if any(Trigger_An[foo] < i*tick < Trigger_Aus[foo]  for foo in np.arange(len(Trigger_Aus)-1)):\n",
    "                ON.append(i)\n",
    "            elif any(Trigger_Aus2[foo]  < i*tick < Trigger_An[foo]  for foo in np.arange(len(Trigger_An))):\n",
    "                OFF.append(i)\n",
    "        ONdic[key]=np.asarray(ON)\n",
    "        OFFdic[key]=np.asarray(OFF)\n",
    "    \n",
    "    return ONdic, OFFdic\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def extract_waveforms(signal, fs, spikes_idx, pre, post):\n",
    "    \"\"\"\n",
    "    Extract spike waveforms as signal cutouts around each spike index as a spikes x samples numpy array\n",
    "\n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param spikes_idx: The sample index of all spikes as a 1-dim numpy array\n",
    "    :param pre: The duration of the cutout before the spike in seconds\n",
    "    :param post: The duration of the cutout after the spike in seconds\n",
    "    \"\"\"\n",
    "    cutouts = []\n",
    "    pre_idx = int(pre * fs)\n",
    "    post_idx = int(post * fs)\n",
    "    for index in spikes_idx:\n",
    "        if index-pre_idx >= 0 and index+post_idx <= signal.shape[0]:\n",
    "            cutout = signal[int((index-pre_idx)):int((index+post_idx))]\n",
    "            cutouts.append(cutout)\n",
    "    if len(cutouts)>0:\n",
    "        return np.stack(cutouts)\n",
    "    \n",
    " \n",
    "#@jit(nopython=True)    \n",
    "def plot_waveforms(cutouts, fs, pre, post, n=100, color='k', show=True):\n",
    "    \"\"\"\n",
    "    Plot an overlay of spike cutouts\n",
    "\n",
    "    :param cutouts: A spikes x samples array of cutouts\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param pre: The duration of the cutout before the spike in seconds\n",
    "    :param post: The duration of the cutout after the spike in seconds\n",
    "    :param n: The number of cutouts to plot, or None to plot all. Default: 100\n",
    "    :param color: The line color as a pyplot line/marker style. Default: 'k'=black\n",
    "    :param show: Set this to False to disable showing the plot. Default: True\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = cutouts.shape[0]\n",
    "    n = min(n, cutouts.shape[0])\n",
    "    time_in_us = np.arange(-pre*1000, post*1000, 1e3/fs)\n",
    "    if show:\n",
    "        _ = plt.figure(figsize=(12,6))\n",
    "\n",
    "    for i in range(n):\n",
    "        _ = plt.plot(time_in_us, cutouts[i,]*1e6, color, linewidth=1, alpha=0.3)\n",
    "        _ = plt.xlabel('Time (%s)' % ureg.ms)\n",
    "        _ = plt.ylabel('Voltage (%s)' % ureg.uV)\n",
    "        _ = plt.title('Cutouts')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_next_maximum(signal, index, max_samples_to_search):\n",
    "    \"\"\"\n",
    "    Returns the index of the next maximum in the signal after an index\n",
    "\n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param index: The scalar index\n",
    "    :param max_samples_to_search: The number of samples to search for a \n",
    "                                    minimum after the index\n",
    "    \"\"\"\n",
    "    search_end_idx = min(index + max_samples_to_search, signal.shape[0])\n",
    "    max_idx = np.argmax(signal[index:search_end_idx])\n",
    "    return index + max_idx\n",
    "\n",
    "\n",
    "\n",
    "def lfp_crossing_detection(lowpass_filtered_signal, lfp_threshold, minimal_length = 0.05):\n",
    "    \n",
    "    '''\n",
    "    parameters \n",
    "    \n",
    "    lowpass_filtered_signal : array like / list\n",
    "        the lowpass filtered signal which is considered as the LFP\n",
    "    \n",
    "    lfp_threshold : float / int\n",
    "        the threshold when there is a crossing we regard it as LFP\n",
    "        deviation\n",
    "        \n",
    "    minimal_length : float\n",
    "        minimal length of a LFP deviation to be considered relevant,\n",
    "        default is 50ms\n",
    "        the value is given in seconds\n",
    "        \n",
    "    _________\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    lfp_down_crossing : list\n",
    "        list of tuples (a,b) with a start of a deviation, b stop in seconds\n",
    "        \n",
    "    lfp_up_crossing : list\n",
    "        analogue to lfp_down_crossing\n",
    "        \n",
    "    amplitudes_down : list\n",
    "        every down crossing has its local minimum which is the maximal negative amplitude\n",
    "    \n",
    "    \n",
    "    amplitudes_down : list\n",
    "        every up crossing has its local minimum which is the maximal negative amplitude\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # dicts will have tuples with a start and stop of the lfp crossing\n",
    "    lfp_up_crossing = []\n",
    "    lfp_down_crossing = []\n",
    "    amplitudes_up = []\n",
    "    amplitudes_down = []\n",
    "    \n",
    "    # lfp crosses below threshold\n",
    "    for i in range(0, len(lowpass_filtered_signal)-1):\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        if (lowpass_filtered_signal[i] < -lfp_threshold) and (lowpass_filtered_signal[i-1] >= -lfp_threshold):\n",
    "            start = i\n",
    "            while (lowpass_filtered_signal[i] < -lfp_threshold) and (i < len(lowpass_filtered_signal)-1):\n",
    "                stop = i\n",
    "                i += 1\n",
    "            # filter for at least 50ms  of LFP deviation\n",
    "            start_seconds = start*scale_factor_for_second*tick + time_in_sec[0] #added since recording do not always start at 0\n",
    "            stop_seconds = stop*scale_factor_for_second*tick +time_in_sec[0]#added since recording do not always start at 0\n",
    "            difference_seconds = stop_seconds - start_seconds\n",
    "            if difference_seconds >= 0.05: # in seconds --> 50 ms\n",
    "            \n",
    "                lfp_down_crossing.append((start_seconds, stop_seconds))\n",
    "                amplitude_point = get_next_minimum(lowpass_filtered_signal, start, stop-start)\n",
    "                amplitude_down = lowpass_filtered_signal[amplitude_point]\n",
    "                amplitudes_down.append(amplitude_down)\n",
    "            \n",
    "    # lfp crosses above threshold\n",
    "    \n",
    "    for i in range(0, len(lowpass_filtered_signal)-1):\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        if (lowpass_filtered_signal[i] > lfp_threshold) and (lowpass_filtered_signal[i-1] <= lfp_threshold):\n",
    "            start = i\n",
    "            while (lowpass_filtered_signal[i] > lfp_threshold) and (i < len(lowpass_filtered_signal)-1):\n",
    "                stop = i\n",
    "                i += 1\n",
    "            # filter for at least 50ms  of LFP deviation\n",
    "            start_seconds = start*scale_factor_for_second*tick +time_in_sec[0]#added since recording do not always start at 0\n",
    "            stop_seconds = stop*scale_factor_for_second*tick +time_in_sec[0]#added since recording do not always start at 0\n",
    "            difference_seconds = stop_seconds - start_seconds\n",
    "            if difference_seconds >= 0.05: # in seconds --> 50 ms\n",
    "            \n",
    "                lfp_up_crossing.append((start_seconds, stop_seconds))\n",
    "                amplitude_point = get_next_maximum(lowpass_filtered_signal, start, stop-start)\n",
    "                amplitude_up = lowpass_filtered_signal[amplitude_point]\n",
    "                amplitudes_up.append(amplitude_up)\n",
    "\n",
    "\n",
    "    return lfp_down_crossing, lfp_up_crossing, amplitudes_down, amplitudes_up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0cb981-41a6-46f6-a033-e0e238c6b652",
   "metadata": {},
   "source": [
    "## Loading the data and start to work with it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a070f-ab7e-4917-864b-41b3310745f6",
   "metadata": {},
   "source": [
    "We set our low and hightcuts for the filter in Hz, then get a list of all files from our rawdata (.h5 is actually already preprocessed, but will be called rawdata from here on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d880ef47-5030-42fa-a4f9-e480e1f23031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x213d13bdb50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# to save memory:\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "# set filter cuts in Hz\n",
    "lowcut = 150\n",
    "highcut = 4500\n",
    "\n",
    "# Length of cutouts around shapes\n",
    "pre = 0.001 # 1 ms\n",
    "post= 0.002 # 2 ms\n",
    "\n",
    "# divide recording in n seconds long subrecordings\n",
    "dividing_seconds = 120\n",
    "\n",
    "# get filelist\n",
    "os.chdir(inputdirectory)\n",
    "filelist= glob.glob(\"*.h5\")\n",
    "\n",
    "\n",
    "resting_spikedic={}\n",
    "spikedic={}\n",
    "spikedic_MAD={}\n",
    "artefactsdic_MAD={}\n",
    "cutouts_dic ={} \n",
    "keylist = []\n",
    "\n",
    "lfp_ups = {}\n",
    "lfp_downs = {}\n",
    "lfp_amplitudes_up = {}\n",
    "lfp_amplitueds_down = {}\n",
    "\n",
    "cs_lfp_ups = {}\n",
    "cs_lfp_downs = {}\n",
    "cs_lfp_amplitudes_up = {}\n",
    "cs_lfp_amplitudes_down = {}\n",
    "\n",
    "lowpass_signal_dic = {}\n",
    "bandpass_signal_dic = {}\n",
    "convolved_lowpass_signal_dic = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96254df7-45e5-4b82-8f8a-5157572565b2",
   "metadata": {},
   "source": [
    "Overview of all files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30eaba54-6775-4426-9eb4-7d72263c84cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2021-05-17T11-08-01__cortex_div11_aCSF_ID046_nodrug_spont_1__.h5',\n",
       " '2021-05-17T11-28-41__cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1__.h5',\n",
       " '2021-05-17T11-52-18__cortex_div11_aCSF_ID046_reWashaCSF_spont_1__.h5',\n",
       " '2021-05-17T11-57-03__cortex_div11_aCSF_ID046_reWashaCSF_spont_2__.h5',\n",
       " '2021-05-17T12-21-29__cortex_div11_hCSF_ID046_nodrug_spont_2__.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c1740-0a02-48f3-bca0-e745cb04fa19",
   "metadata": {},
   "source": [
    "we concentrate on the recording with 30ÂµM Norepinphrine since it exhibits \n",
    "interesting network activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a677ab-6495-458a-bedd-ea84eb6c0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = filelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6389b76-a8e1-432e-9415-9a14894099de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file: 2021-05-17T11-28-41__cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1__.h5\n",
      "Recording_0 <HDF5 group \"/Data/Recording_0\" (2 members)>\n",
      "{0: <Recording label=, AnalogStreams=3, EventStreams=1, duration_time=120400000 microsecond>}\n",
      "\n",
      "2021-05-17 11:28:41.983040\n",
      "Montag, 17. Mai 2021\n",
      "637568477219830367\n",
      "93cc2871-fddc-4f8a-a10c-710223cf8328\n",
      "256MEA\n",
      "\n",
      "MEA_256MEA_MEA2100_252_6\n",
      "Multi Channel Experimenter\n",
      "2.15.0.20098\n",
      "Stream_0 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_0\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (252, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (252,), type \"|V108\">\n",
      "Stream_1 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_1\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (1, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (1,), type \"|V108\">\n",
      "Stream_2 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_2\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (1, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (1,), type \"|V108\">\n",
      "In total 3 analog_streams were identified.\n",
      "\n",
      "analog_stream Nr. 0: \n",
      "datapoints measured = 3010000\n",
      "sampling frequency = 25000.000000000004 hertz\n",
      "ticks = 40\n",
      "total recordingtime is: 120.39999999999999seconds \n",
      "\n",
      "analog_stream Nr. 1: \n",
      "datapoints measured = 3010000\n",
      "sampling frequency = 25000.000000000004 hertz\n",
      "ticks = 40\n",
      "total recordingtime is: 120.39999999999999seconds \n",
      "\n",
      "analog_stream Nr. 2: \n",
      "datapoints measured = 3010000\n",
      "sampling frequency = 25000.000000000004 hertz\n",
      "ticks = 40\n",
      "total recordingtime is: 120.39999999999999seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create empty dictionaries / lists to be filled in further analysis\n",
    "resting_spikedic={}\n",
    "spikedic={}\n",
    "cutouts_dic ={} \n",
    "keylist = []\n",
    "\n",
    "filename = file\n",
    "filedatebase = filename.split('T')[0]\n",
    "filenamebase = filename.split('__')[1]\n",
    "filebase = filedatebase + '_' + filenamebase\n",
    "\n",
    "# print raw channel infos\n",
    "print('Working on file: ' +filename)\n",
    "channel_raw_data = McsPy.McsData.RawData(filename)\n",
    "get_channel_infos(inputdirectory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b5dc989-c2c6-4a3d-968b-eabff1dd2eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording_0 <HDF5 group \"/Data/Recording_0\" (2 members)>\n",
      "Stream_0 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_0\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (252, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (252,), type \"|V108\">\n",
      "Stream_1 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_1\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (1, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (1,), type \"|V108\">\n",
      "Stream_2 <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_2\" (3 members)>\n",
      "ChannelData <HDF5 dataset \"ChannelData\": shape (1, 3010000), type \"<i4\">\n",
      "ChannelDataTimeStamps <HDF5 dataset \"ChannelDataTimeStamps\": shape (1, 3), type \"<i8\">\n",
      "InfoChannel <HDF5 dataset \"InfoChannel\": shape (1,), type \"|V108\">\n"
     ]
    }
   ],
   "source": [
    "# import the raw data\n",
    "analog_stream_0 = channel_raw_data.recordings[0].analog_streams[0]\n",
    "stream = analog_stream_0\n",
    "for key in stream.channel_infos.keys():\n",
    "    keylist.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29de283e-df3c-48e7-ae69-482f69db0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = keylist[0]\n",
    "tick = stream.channel_infos[channel_id].info['Tick']\n",
    "time = stream.get_channel_sample_timestamps(channel_id)\n",
    "first_recording_timepoint = time[0][0]\n",
    "scale_factor_for_second = Q_(1,time[1]).to(ureg.s).magnitude\n",
    "time_in_sec = time[0]*scale_factor_for_second\n",
    "timelengthrecording_ms = time[0][-1]+tick\n",
    "timelengthrecording_s = (time[0][-1]+tick)*scale_factor_for_second\n",
    "fs = int(stream.channel_infos[channel_id].sampling_frequency.magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab0ee3cb-924e-4186-b26d-4943cc2535ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_stream_0_data = analog_stream_0.channel_data\n",
    "np_analog_stream_0_data = np.transpose(\n",
    "    channel_raw_data.recordings[0].analog_streams[0].channel_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9661dd2a-8aeb-4d01-9864-9a2d617594a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retranspose the data to make it readable for the filter\n",
    "np_analog_for_filter = np.transpose(np_analog_stream_0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35bbfecc-6a89-49b6-9b27-cbc9aef1ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete these streams to save memory\n",
    "del np_analog_stream_0_data\n",
    "del analog_stream_0_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496251cd-9763-47d2-9c81-d0ffc57a5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for longer recordings we need to subdivide the signal into snippets \n",
    "# 120seconds per snippet was defined above (dividing seconds)\n",
    "signal_cuts = []\n",
    "    \n",
    "starting_point = 0\n",
    "stopping_point = 0\n",
    "while starting_point < timelengthrecording_s:\n",
    "    if starting_point + dividing_seconds >= int(timelengthrecording_s):\n",
    "        stopping_point = int(timelengthrecording_s)\n",
    "\n",
    "    else:\n",
    "        stopping_point =stopping_point + dividing_seconds\n",
    "    signal_cuts.append((starting_point, stopping_point))\n",
    "\n",
    "    # set the window one step further:\n",
    "    starting_point = starting_point + dividing_seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "188d0ec4-3b75-4226-93b8-d02593b29b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 120), (120, 120)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948fa4d0-ba9f-4755-a99c-60bcfcaa94e2",
   "metadata": {},
   "source": [
    "In this example, the second signal cut will only have a few microseconds of data. We will discard this and concentrate on the first 120 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc9e8be8-e85e-4009-8391-2bcf68e11f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = signal_cuts[0]\n",
    "starting_point = i[0]\n",
    "stopping_point = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5548d9cd-f4fc-4154-a702-2a99ab682091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory D:\\MEA_DATA_Aachen\\ANALYZED\\ID046_analysiert_22102021\\analysis_17112021\\2021-05-17_cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1_from_0_to_120_analyzed_on_17112021 failed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%d%m%Y\")\n",
    "\n",
    "# we create an outpath per subdivided recording part\n",
    "\n",
    "outpath = Path(\n",
    "    outputdirectory, filebase + '_from_'+str(starting_point) + \n",
    "    '_to_' +str(stopping_point) + '_analyzed_on_'+timestr)\n",
    "try:\n",
    "    os.mkdir(outpath)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % outpath)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % outpath)\n",
    "\n",
    "os.chdir(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f591f7-7891-44ba-8f6e-4f00865378a2",
   "metadata": {},
   "source": [
    "## We will now go trough the analysis for one channel.\n",
    "\n",
    "Please note, this is normally done within a for-loop, so that all 252 channels can be analysed at once and saved for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d017cc79-7431-4f79-9303-57f767efb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # to get the first channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844739a-9468-4e71-aa22-a51960103158",
   "metadata": {},
   "source": [
    "### Spike Detection using the MAD threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b4e7aca-bd5d-4be4-8444-7c69396111b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 channel: G13\n"
     ]
    }
   ],
   "source": [
    "cutouts_dic ={}\n",
    "            \n",
    "channel_idx = i\n",
    "labellist = get_MEA_Channel_labels(np_analog_for_filter)\n",
    "signal_in_uV, time_in_sec, sampling_frequency, scale_factor_for_second = get_MEA_Signal(\n",
    "    analog_stream_0, channel_idx, from_in_s=starting_point,\n",
    "    to_in_s=stopping_point\n",
    "    )\n",
    "bandpassfilteredsignal = butter_bandpass_filter(\n",
    "    signal_in_uV, lowcut, highcut, sampling_frequency\n",
    "    )\n",
    "\n",
    "# This Part is for finding MAD spikes + plotting\n",
    "noise_mad = np.median(np.absolute(bandpassfilteredsignal)) / 0.6745\n",
    "threshold = -5* noise_mad\n",
    "artefact_threshold = -8* noise_mad\n",
    "crossings = detect_threshold_crossings(\n",
    "    bandpassfilteredsignal, sampling_frequency, \n",
    "    threshold, dead_time=0.001\n",
    "    )\n",
    "spikes=align_to_minimum(\n",
    "    bandpassfilteredsignal, fs, crossings, search_range=0.003, \n",
    "    first_time_stamp=first_recording_timepoint\n",
    "    )\n",
    "\n",
    "if len(spikes) < 10:\n",
    "    artefact_crossings = detect_threshold_crossings(\n",
    "        bandpassfilteredsignal, sampling_frequency, \n",
    "        artefact_threshold, dead_time=0.001\n",
    "        )\n",
    "    artefacts = align_to_minimum(\n",
    "        bandpassfilteredsignal, fs, artefact_crossings, search_range=0.003, \n",
    "        first_time_stamp=first_recording_timepoint\n",
    "        )\n",
    "\n",
    "\n",
    "# this line accoutns for a starting point of the recording that is != 0\n",
    "spikes = spikes + int(time_in_sec[0]/(scale_factor_for_second*tick)) \n",
    "channellabel = labellist[i]\n",
    "spikedic_MAD[channellabel] = spikes\n",
    "bandpass_signal_dic[channellabel] = bandpassfilteredsignal\n",
    "#artefactsdic_MAD[channellabel] = artefacts\n",
    "print('iteration ' + str(i) + ' channel: ' +str(channellabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72d7a64f-7172-460b-b6d6-5900a0c6b0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if any spikes were detected:\n",
    "len(spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843c97f-1486-473b-a618-678e9fc12124",
   "metadata": {},
   "source": [
    "### Next: Crossings of the Local Field Potential (LFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "107f2985-8a6f-4739-9830-441a51589a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = timelengthrecording_s         # Sample Period\n",
    "fs = fs      # sample rate, Hz\n",
    "cutoff = 100  # desired cutoff frequency of the filter of lowpass\n",
    "nyq = 0.5 * fs  # Nyquist Frequency\n",
    "order = 2       # sin wave can be approx represented as quadratic\n",
    "n = int(T * fs) # total number of samples\n",
    "\n",
    "butter_lowpass_filtered_signal = butter_lowpass_filter(signal_in_uV, cutoff, fs, order)\n",
    "\n",
    "\n",
    "lfp_std = np.std(butter_lowpass_filtered_signal)\n",
    "lfp_mean = np.mean(butter_lowpass_filtered_signal)\n",
    "threshold_LFP = 3*lfp_std\n",
    "\n",
    "\n",
    "down_cross, up_cross, amp_down, amp_up = lfp_crossing_detection(\n",
    "    butter_lowpass_filtered_signal, threshold_LFP, minimal_length=0.03)\n",
    "\n",
    "\n",
    "# this is also done for a convolved, i.e., smoothed version of the signal\n",
    "#Modulation for the LFP Start\n",
    "\n",
    "convolved_signal = np.convolve(butter_lowpass_filtered_signal, np.ones(3000)/3000, mode='full')\n",
    "\n",
    "\n",
    "length_cutter = len(butter_lowpass_filtered_signal)\n",
    "\n",
    "cs = convolved_signal[:length_cutter]\n",
    "\n",
    "cs_threshold = np.std(cs)*2\n",
    "\n",
    "cs_down_cross, cs_up_cross, cs_amp_down, cs_amp_up = lfp_crossing_detection(\n",
    "    convolved_signal, cs_threshold, minimal_length=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1be3cf21-5a22-4f64-bd6e-0889abb1dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to reuse most of the data just calculated\n",
    "# therefore, they are stored in a dictionary with the channellabel\n",
    "lfp_ups[channellabel] = up_cross\n",
    "lfp_downs[channellabel] = down_cross\n",
    "lfp_amplitudes_up[channellabel] = amp_up\n",
    "lfp_amplitueds_down[channellabel] = amp_down\n",
    "\n",
    "cs_lfp_ups[channellabel] = cs_up_cross\n",
    "cs_lfp_downs[channellabel] = cs_down_cross\n",
    "cs_lfp_amplitudes_up[channellabel] = cs_amp_up\n",
    "cs_lfp_amplitudes_down[channellabel] = cs_amp_down\n",
    "\n",
    "lowpass_signal_dic[channellabel] = butter_lowpass_filtered_signal\n",
    "convolved_lowpass_signal_dic[channellabel] = convolved_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fc39d57-3070-4c11-bdeb-9f3d1beb1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'G13': [(90.56384, 90.90379999999999),\n",
       "  (106.78151999999999, 107.05624),\n",
       "  (107.05764, 107.14112)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us look at one example:\n",
    "lfp_ups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa599e-1d44-45a3-a38b-6fa75799787d",
   "metadata": {},
   "source": [
    "so the channel G13 has upcrossings of the LFP at three different times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e60881b-1290-4a0b-aa39-aa06bd07d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(spikes) > 3:\n",
    "\n",
    "    #only extract cutouts when they are relevant\n",
    "    # extracting the cutouts takes a lot of working memory\n",
    "    cutouts = extract_waveforms(\n",
    "            bandpassfilteredsignal, sampling_frequency, spikes, \n",
    "            pre, post\n",
    "            )\n",
    "    cutouts_dic[channellabel] = cutouts\n",
    "\n",
    "\n",
    "    plt.style.use(\"seaborn-white\")\n",
    "\n",
    "\n",
    "    # figure 1: signal with threshold\n",
    "    fig1, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "    ax = plt.plot(time_in_sec, bandpassfilteredsignal, c=\"#45858C\")\n",
    "    ax = plt.plot([time_in_sec[0], time_in_sec[-1]], [threshold, threshold], c=\"#297373\")\n",
    "    ax = plt.plot(spikes*tick*scale_factor_for_second, [threshold-1]*(spikes*tick*scale_factor_for_second).shape[0], 'ro', ms=2, c=\"#D9580D\")\n",
    "    ax = plt.title('Channel %s' %channellabel)\n",
    "    ax = plt.xlabel('Time in Sec, Threshold: %s' %threshold)\n",
    "    ax = plt.ylabel('Âµ volt')\n",
    "    ax = plt.plot(time_in_sec, butter_lowpass_filtered_signal, c='#F29829', linewidth=0.5)\n",
    "    for i in down_cross:\n",
    "        ax = plt.axvspan(i[0], i[1], color='#5D7CA6', alpha=0.2)\n",
    "    for i in up_cross:\n",
    "        ax = plt.axvspan(i[0], i[1], color='#BF214B', alpha=0.2)\n",
    "    fig_1_name = filebase+'_signal_'+channellabel+'MAD_THRESHOLD.png'\n",
    "    if not os.path.exists(outpath):\n",
    "        os.mkdir(outpath) \n",
    "    fullfig_1_name = Path(outpath, fig_1_name)\n",
    "    fig1.savefig(fullfig_1_name)\n",
    "    plt.close(fig1) \n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c13050-5f50-4d90-83ee-5dce1ae887ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\MEA_DATA_Aachen\\\\ANALYZED\\\\ID046_analysiert_22102021\\\\analysis_17112021\\\\2021-05-17_cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1_from_0_to_120_analyzed_on_17112021\\\\2021-05-17_cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1_waveforms_G13MAD_THRESHOLD.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-ab4297a4641a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mfullfig_2_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig_2_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfig2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullfig_2_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3003\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3005\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2253\u001b[0m                 \u001b[1;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2255\u001b[1;33m                     result = print_method(\n\u001b[0m\u001b[0;32m   2256\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2257\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \"\"\"\n\u001b[0;32m    508\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         mpl.image.imsave(\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1614\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dpi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1616\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2153\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\MEA_DATA_Aachen\\\\ANALYZED\\\\ID046_analysiert_22102021\\\\analysis_17112021\\\\2021-05-17_cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1_from_0_to_120_analyzed_on_17112021\\\\2021-05-17_cortex_div11_aCSF_ID046_30ÂµMNorepinephrine_spont_1_waveforms_G13MAD_THRESHOLD.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "#figure 2: waveforms \n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(12,6))\n",
    "#ax2 is a plot of the waveform cutouts\n",
    "n = 100\n",
    "n = min(n, cutouts.shape[0])\n",
    "time_in_us = np.arange(-pre*1000, post*1000, 1e3/fs)\n",
    "cutout_mean = np.mean(cutouts, axis=0)\n",
    "for i in range(n):\n",
    "    ax2 = plt.plot(time_in_us, cutouts[i,]*1e6, color='black', linewidth=1, alpha=0.3)\n",
    "    ax2 = plt.plot(time_in_us, cutout_mean*1e6, color=\"red\", linewidth=1, alpha=0.3)\n",
    "    ax2 = plt.xlabel('Time (%s)' % ureg.ms)\n",
    "    ax2 = plt.ylabel('Voltage (%s)' % ureg.uV)\n",
    "    ax2 = plt.title('Cutouts of Channel %s' %channellabel)\n",
    "\n",
    "fig_2_name = filebase+'_waveforms_'+channellabel+'MAD_THRESHOLD.png'\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath) \n",
    "fullfig_2_name = Path(outpath, fig_2_name)\n",
    "fig2.savefig(fullfig_2_name)\n",
    "plt.close(fig2) \n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579fbac-a54f-4bdb-91e5-158eb54a6233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
